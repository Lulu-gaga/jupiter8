#!/usr/bin/env python
# Standard imports
import os
import argparse
import logging
import json
import datetime

# External dependencies
import pymongo
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix

# Local imports
from aconv import get_aconv
from small import get_model
from data.load2 import load_images, get_test_generator
from utils.argutils import valid_path

DATABASE = 'mstar2'
COLLECTION = 'targets'
DEP_ANGLE_TEST = '15_DEG'

log = logging.getLogger(__name__)

def get_parser():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('outdir', type=valid_path,
        help="""Output directory for test/training results""")

    parser.add_argument('weights', type=valid_path,
        help="""Weights file to load""")

    parser.add_argument('label_map', type=valid_path,
        help="""Label map json file""")

    parser.add_argument('--batch', type=int, default=32,
        help="""Batch size""")

    parser.add_argument('--prefix', type=str, default=None,
        help="""Prefix to add to created session output subdirectory""")
    return parser


def main(args):
    # Make subdirectory for session
    tstamp = datetime.datetime.utcnow()
    subdir = tstamp.strftime("%Y%m%d%H%M%S")
    subdir = '.'.join(('test', subdir))
    if args.prefix:
        subdir = '_'.join((args.prefix, subdir))
    subdir = os.path.join(args.outdir, subdir)
    os.mkdir(os.path.join(args.outdir, subdir), 0o755)
    log.info("Results will be logged to %s" % subdir)

    # Setup DB connection
    client = pymongo.MongoClient()
    db = client[DATABASE]
    collection = db[COLLECTION]

    # Query training data
    query = {'depression_angle': DEP_ANGLE_TEST}
    cursor = collection.find(query)

    # Construct data frame
    df = pd.DataFrame(list(cursor))

    # Load images
    log.info("loading images")
    images = load_images(list(df.filename), crop_dim=(128,128))
    log.info("loaded %d images" % len(images))

    # Setup labels
    log.info("configuring labels")
    with open(args.label_map, 'r') as f:
        label_map = json.load(f)
    labels = df.target_class.apply(lambda x: label_map[x])
    log.info("loaded %d labels" % len(labels))

    # Get data generator
    datagen = get_test_generator(images, labels, args.batch)

    # Setup model
    #model = get_aconv((88, 88, 1))
    model=get_model(input_shape=(128,128,1))
    log.info("loading model weights")
    model.load_weights(args.weights)
    model.summary()

    # Evaluate
    log.info("predicting on samples")
    y = model.predict_generator(datagen, steps=datagen.n // args.batch + 1)
    np.savetxt(os.path.join(subdir, 'predictions.log'), y, delimiter=',')
    predictions = np.argmax(y, axis=1)
    print(confusion_matrix(labels, predictions))

    return

if __name__ == '__main__':
    logging.basicConfig(level=20)
    parser = get_parser()
    args = parser.parse_args()
    try:
        main(args)
    except Exception as err:
        log.error(err, exc_info=True)
        exit(1)
    else:
        exit(0)
