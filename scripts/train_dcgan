#!/usr/bin/env python
import os
import sys
import datetime
import argparse
import json

# Keras dependencies
from keras.optimizers import Adam
from keras.models import model_from_json

# Local imports
sys.path.append(os.path.expandvars("$JUPITER8_HOME/python"))
from dcgan.dcgan import DCGAN, get_generator, get_discriminator
from data.load_mstar import load_data

def valid_path(path):
    p = os.path.expandvars(path)
    if not os.path.exists(p):
        raise ValueError("%s does not exist" % p)
    return p

def get_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument('target', choices=['T72', 'BMP2', 'BTR70'], help="""target class""")
    parser.add_argument('outdir', type=str, default='.',
        help="""results output directory""")
    parser.add_argument('--rows', type=int, default=128, help="""image rows""")
    parser.add_argument('--cols', type=int, default=128, help="""image columns""")
    parser.add_argument('--channels', type=int, default=1, help="""image channels""")
    parser.add_argument('--latent-dim', dest='latent_dim', type=int, default=100,
        help="""length of generator input noise vector""")
    parser.add_argument('--epochs', type=int, default=4000,
        help="""number of training epochs""")
    parser.add_argument('--batch-size', dest='batch', type=int, default=32,
        help="""batch size""")
    parser.add_argument('--learn-rate', dest='learning', type=float, default=0.0002,
        help="""optimizer learning rate""")
    parser.add_argument('--gen-json-model', dest='gen_json_model', type=valid_path,
        default=None,
        help="""path to JSON file describing the un-built generator model to use""")
    parser.add_argument('--dis-json-model', dest='dis_json_model', type=valid_path,
        default=None,
        help="""path to JSON file describing the un-built discriminator model to use""")
    return parser

def main(args):
    optimizer = Adam(args.learning, 0.5)
    img_shape = (args.rows, args.cols, args.channels)

    # Build network
    if args.gen_json_model is not None:
        with open(gen_json_file, 'r') as f:
            gen_unbuilt = model_from_json(f.read())
    else:
        gen_unbuilt = get_generator(args.latent_dim, args.channels)

    if args.dis_json_model is not None:
        with open(dis_json_file, 'r') as f:
            dis_unbuilt = model_from_json(f.read())
    else:
        dis_unbuilt = get_discriminator(img_shape)
    network = DCGAN(args.latent_dim, img_shape, gen_unbuilt, dis_unbuilt, optimizer, quiet=False)
    network.set_outdir(args.outdir)

    # Save unbuilt models
    model_g = gen_unbuilt.to_json()
    with open(os.path.join(args.outdir, "gen_unbuilt_model.json"), 'w') as f:
        f.write(model_g)
    model_d = dis_unbuilt.to_json()
    with open(os.path.join(args.outdir, "dis_unbuilt_model.json"), 'w') as f:
        f.write(model_d)

    # Train network
    data = load_data(args.target, label='train')
    try:
        network.train(data, args.epochs, args.batch)
    except KeyboardInterrupt:
        print("Training stopped due to Keyboard Interrupt")
    else:
        print("Training complete")

    # Log results
    with open(os.path.join(args.outdir, "results.log"), 'w') as f:
        f.write(json.dumps(network.results))

    # Save weights
    network.generator.save_weights(os.path.join(args.outdir, "generator_weights.h5"))
    network.discriminator.save_weights(os.path.join(args.outdir, "discriminator_weights.h5"))

if __name__ == '__main__':
    parser = get_parser()
    args = parser.parse_args()
    main(args)
    sys.exit(0)
