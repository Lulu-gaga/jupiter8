#!/usr/bin/env python
"""Synthesize images using trained GAN
"""
# Standard imports
import os
import sys
import argparse
import logging
import yaml

# External dependencies
import pymongo
import numpy as np
import matplotlib.pyplot as plt
from keras.models import model_from_json

# Local imports
from jup8.dcgan.dcgan import build_generator, build_discriminator

LATENT_DIM = 100
TARGETS = [
    "BTR_60",
    "2S1",
    "BRDM_2",
    "D7",
    "T62",
    "ZIL131",
    "ZSU_23_4",
    "BMP2",
    "BTR70",
    "T72"
]
GEN_MODEL = "gen_unbuilt_model.json"
GEN_WEIGHTS = "generator_weights.h5"
DIS_MODEL = "dis_unbuilt_model.json"
DIS_WEIGHTS = "discriminator_weights.h5"
CONFIG = "config.yaml"
QUALITY = 0.9
DATABASE = 'mstar2'
COLLECTION = 'synthetics'
TRAINING_SAMPLES = 'training_samples.yaml'

log = logging.getLogger(__name__)


def valid_path(path):
    p = os.path.expandvars(path)
    if not os.path.exists(p):
        raise ValueError("%s does not exist" % p)
    return p


def valid_quality(x):
    if (x < 0.0) or (x >= 1.0):
        raise ValueError("Synth quality must be in range [0.0, 1.0]")
    return x


def get_parser():
    """Returns command line parser
    """
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('target', choices=TARGETS,
        help="""Target class to synthesize""")
    parser.add_argument('qty', type=int,
        help="""Quantity of images to synthesize""")
    parser.add_argument('modeldir', type=valid_path,
        help="""Directory location of model weights and config files""")
    parser.add_argument('outdir', type=valid_path,
        help="""directory to write images to""")
    #
    # Database options
    #
    dbgroup = parser.add_argument_group('Database Options')
    dbgroup.add_argument('--database', type=str, default=DATABASE,
        help="""Database to write synthetics metadata to""")
    dbgroup.add_argument('--collection', type=str, default=COLLECTION,
        help="""Collection to write sythetics metadata to""")
    #
    # Miscellaneous options
    #
    parser.add_argument('--quality', type=valid_quality, default=QUALITY,
        help="""Minimum required quality of synthetic (based on discriminator
                prediction). Must be in range [0.0, 1.0)""")
    parser.add_argument('--debug', action='store_true',
        help="""Turn on debugging""")
    return parser


def main(args):
    # Confirm correct model provided for target class
    configfile = os.path.join(args.modeldir, CONFIG)
    log.info("Parsing config file %s" % configfile)
    with open(configfile, 'r') as f:
        config = yaml.load(f)
    if args.target != config['target']:
        raise ValueError("Provided target (%s) does not match config target (%s)"
            % (args.target, config['target']))
    # Confirm list of training samples for model is available
    sources = os.path.join(args.modeldir, TRAINING_SAMPLES)
    if not os.path.exists(sources):
        raise RuntimeError("Could not locate training samples file for model (%s)" % sources)

    #
    # Setup database connection
    #
    client = pymongo.MongoClient()
    if args.database not in client.database_names():
        raise ValueError("Database %s does not exist" % args.database)
    db = client[args.database]
    if args.collection not in db.collection_names():
        log.warn("Collection %s does not exist in database %s, creating new collection"
            % (args.collection, args.database))

    #
    # Build generator
    #
    genmodelfile = os.path.join(args.modeldir, GEN_MODEL)
    log.info("Loading unbuilt generator model %s" % genmodelfile)
    with open(genmodelfile, 'r') as f:
        generator = model_from_json(f.read())
    log.info("Building generator model")
    generator = build_generator(generator, LATENT_DIM)
    genweightsfile = os.path.join(args.modeldir, GEN_WEIGHTS)
    log.info("Loading generator model weights %s" % genweightsfile)
    generator.load_weights(genweightsfile)

    #
    # Build discriminator
    #
    dismodelfile = os.path.join(args.modeldir, DIS_MODEL)
    log.info("Loading unbuilt discriminator model %s" % dismodelfile)
    with open(dismodelfile, 'r') as f:
        discriminator = model_from_json(f.read())
    log.info("Building discriminator model")
    shape = (config['cols'], config['rows'], 1)
    discriminator = build_discriminator(discriminator, shape)
    disweightsfile = os.path.join(args.modeldir, DIS_WEIGHTS)
    log.info("Loading discriminator model weights %s" % disweightsfile)
    discriminator.load_weights(disweightsfile)
    
    #
    # Generate images
    #
    counter = 0
    documents = []
    while counter < args.qty:
        noise = np.random.normal(0, 1, (1, LATENT_DIM))
        synth = generator.predict(noise)

        ## Check against discriminator
        #test = discriminator.predict(synth)
        #log.debug("test score: %f" % test)
        #if test < args.quality:
        #    continue

        # Rescale image magnitudes to [0,1]
        synth = 0.5 * synth + 0.5

        # Save image
        name = '%s_synth_%d.png' % (args.target, counter)
        fname = os.path.join(args.outdir, name)
        log.debug("Saving image %s" % fname)
        plt.imsave(fname, synth[0,:,:,0], cmap='gray')
        counter +=1 # Increment counter

        # Make database entry for image
        d = {}
        d['filename'] = fname
        d['generator_model'] = genmodelfile
        d['generator_weights'] = genweightsfile
        d['discriminator_model'] = dismodelfile
        d['discriminator_weights'] = disweightsfile
        d['target_class'] = args.target
        d['sources'] = sources
        documents.append(d)
    log.info("Generated %d synthetics for target class %s" % (counter, args.target))

    #
    # Write metadata to DB
    #
    num_inserted = 0
    log.info("Inserting synthetics metadata into the database")
    for doc in documents:
        result = db[args.collection].insert(doc)
        if result: num_inserted +=1
    log.info("Inserted %d of %d documents into the database" % (num_inserted, len(documents)))

    return
        

if __name__ == '__main__':
    # Parse command line
    parser = get_parser()
    args = parser.parse_args()
    # Setup logging
    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    # Main
    try:
        main(args)
    except Exception as err:
        log.error(err, exc_info=args.debug)
        exit(1)
    else:
        exit(0)
