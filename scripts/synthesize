#!/usr/bin/env python
"""Synthesize images using trained GAN
"""
# Standard imports
import os
import sys
import argparse
import logging
import yaml

# External dependencies
import pymongo
import numpy as np
import matplotlib.pyplot as plt
from keras.models import model_from_json

# Local imports
from dcgan.dcgan import build_generator

LATENT_DIM = 100
TARGETS = [
    "BTR_60",
    "2S1",
    "BRDM_2",
    "D7",
    "T62",
    "ZIL131",
    "ZSU_23_4",
    "BMP2",
    "BTR70",
    "T72"
]
GEN_MODEL = "gen_unbuilt_model.json"
GEN_WEIGHTS = "final_generator_weights.h5"
CONFIG = "config.yaml"
TRAINING_SAMPLES = "training_samples.yaml"
DATABASE = 'mstar2'
COLLECTION = 'synthetics'
TRAINING_SAMPLES = 'training_samples.yaml'

log = logging.getLogger(__name__)


def valid_path(path):
    p = os.path.expandvars(path)
    if not os.path.exists(p):
        raise ValueError("%s does not exist" % p)
    return p


def get_parser():
    """Returns command line parser
    """
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('target', choices=TARGETS,
        help="""Target class to synthesize""")
    parser.add_argument('qty', type=int,
        help="""Quantity of images to synthesize""")
    parser.add_argument('modeldir', type=valid_path,
        help="""Directory location of model weights and config files""")
    parser.add_argument('outdir', type=valid_path,
        help="""directory to write images to""")
    #
    # Database options
    #
    dbgroup = parser.add_argument_group('Database Options')
    dbgroup.add_argument('--database', type=str, default=DATABASE,
        help="""Database to write synthetics metadata to""")
    dbgroup.add_argument('--collection', type=str, default=COLLECTION,
        help="""Collection to write sythetics metadata to""")
    #
    # Miscellaneous options
    #
    parser.add_argument('--debug', action='store_true',
        help="""Turn on debugging""")
    parser.add_argument('--prefix', type=str, default=None,
        help="""Prefix to add to synthesize image filenames""")
    return parser


def main(args):
    # Confirm correct model provided for target class
    configfile = os.path.join(args.modeldir, CONFIG)
    log.info("Parsing config file %s" % configfile)
    with open(configfile, 'r') as f:
        config = yaml.load(f)
    if args.target != config['target']:
        raise ValueError("Provided target (%s) does not match config target (%s)"
            % (args.target, config['target']))
    if not config['num_samples']:
        all_samples_used = True
    else:
        all_samples_used = False
    # Get the number of samples the model was trained on
    with open(os.path.join(args.modeldir, TRAINING_SAMPLES), 'r') as f:
        training_samples = yaml.load(f)
    num_samples_trained_with = len(training_samples['filenames'])
    # Confirm list of training samples for model is available
    sources = os.path.join(args.modeldir, TRAINING_SAMPLES)
    if not os.path.exists(sources):
        raise RuntimeError("Could not locate training samples file for model (%s)" % sources)

    #
    # Setup database connection
    #
    client = pymongo.MongoClient()
    if args.database not in client.database_names():
        raise ValueError("Database %s does not exist" % args.database)
    db = client[args.database]
    if args.collection not in db.collection_names():
        log.warn("Collection %s does not exist in database %s, creating new collection"
            % (args.collection, args.database))

    #
    # Build generator
    #
    genmodelfile = os.path.join(args.modeldir, GEN_MODEL)
    log.info("Loading unbuilt generator model %s" % genmodelfile)
    with open(genmodelfile, 'r') as f:
        generator = model_from_json(f.read())
    log.info("Building generator model")
    generator = build_generator(generator, LATENT_DIM)
    genweightsfile = os.path.join(args.modeldir, GEN_WEIGHTS)
    log.info("Loading generator model weights %s" % genweightsfile)
    generator.load_weights(genweightsfile)

    #
    # Generate images
    #
    documents = []
    for i in xrange(args.qty):
        noise = np.random.normal(0, 1, (1, LATENT_DIM))
        synth = generator.predict(noise)

        # Rescale image magnitudes to [0,1]
        synth = 0.5 * synth + 0.5

        # Save image
        name = '%s_synth_%d.png' % (args.target, i)
        if args.prefix: name = '_'.join((args.prefix, name))
        fname = os.path.join(args.outdir, name)
        log.debug("Saving image %s" % fname)
        plt.imsave(fname, synth[0,:,:,0], cmap='gray')

        # Make database entry for image
        d = {}
        d['filename'] = fname
        d['generator_model'] = genmodelfile
        d['generator_weights'] = genweightsfile
        d['target_class'] = args.target
        d['sources'] = sources
        d['num_samples_trained_with'] = num_samples_trained_with
        d['all_training_samples_used'] = all_samples_used
        documents.append(d)
    log.info("Generated %d synthetics for target class %s" % (args.qty, args.target))

    #
    # Write metadata to DB
    #
    num_inserted = 0
    log.info("Inserting synthetics metadata into the database")
    for doc in documents:
        result = db[args.collection].insert(doc)
        if result: num_inserted +=1
    log.info("Inserted %d of %d documents into the database" % (num_inserted, len(documents)))

    return
        

if __name__ == '__main__':
    # Parse command line
    parser = get_parser()
    args = parser.parse_args()
    # Setup logging
    if args.debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    # Main
    main(args)
    exit(0)
